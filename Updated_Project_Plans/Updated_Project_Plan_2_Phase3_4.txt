ARCHIVED: Pre‑Autopilot‑v2 design doc. Kept for historical context; see `docs/SYSTEM_OVERVIEW.md`, `docs/SYSTEM_MATRIX.md`, `docs/AUTOPILOT_PLAN.md`, `docs/TODO_CHECKLIST.md`, and `docs/PROGRESS.md` for the current state of the system.

Phase 3 – Execution Runs, Steps, Workers, Diffs & Rollback (ultra‑granular)

Goal: go from “assistant suggests commands and file edits” to structured, logged workflows (runs) that can actually touch files and run tests, with diff/rollback and clear UI. This is the Cursor‑like engine.

3.0 Preconditions / sanity checklist

Before Phase 3 work, make sure:

 Backend runs and passes python -m qa.run_smoke. 

SYSTEM_OVERVIEW

 Frontend builds with npm run build. 

USER_MANUAL

 docs/SYSTEM_MATRIX.md is up to date for existing features, especially Files + Terminal. 

API_REFERENCE

3.1 Backend models for runs, steps, dependencies

File: backend/app/db/models.py 

SYSTEM_OVERVIEW

3.1.1 Add TaskDependency (if it doesn’t exist yet)

 Define TaskDependency model:

class TaskDependency(Base):
    __tablename__ = "task_dependencies"

    id = Column(Integer, primary_key=True)
    task_id = Column(Integer, ForeignKey("tasks.id"), nullable=False)
    depends_on_task_id = Column(Integer, ForeignKey("tasks.id"), nullable=False)

    task = relationship("Task", foreign_keys=[task_id])
    depends_on = relationship("Task", foreign_keys=[depends_on_task_id])


 Add index ix_task_dep_task on (task_id, depends_on_task_id).

3.1.2 Define ExecutionRun

 Add model:

class ExecutionRun(Base):
    __tablename__ = "execution_runs"

    id = Column(Integer, primary_key=True)
    project_id = Column(Integer, ForeignKey("projects.id"), nullable=False)
    conversation_id = Column(Integer, ForeignKey("conversations.id"), nullable=True)
    task_id = Column(Integer, ForeignKey("tasks.id"), nullable=True)

    run_type = Column(String, nullable=False)  # e.g. implement_feature, fix_bug, refactor_module, write_docs
    status = Column(String, default="planned")  # planned, running, awaiting_approval, completed, failed, aborted

    started_by = Column(String, nullable=False)  # "user" or "manager"

    error_message = Column(Text, nullable=True)
    meta = Column(JSON, nullable=True)  # timing, token counts, etc.

    touched_files_json = Column(JSON, nullable=True)  # { "path": { "before": "...", "after": "..." }, ... }

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    started_at = Column(DateTime, nullable=True)
    finished_at = Column(DateTime, nullable=True)

    project = relationship("Project")
    conversation = relationship("Conversation")
    task = relationship("Task")
    steps = relationship("ExecutionStep", back_populates="run", cascade="all, delete-orphan")


 Add index ix_execution_runs_project_status = Index(..., "project_id", "status").

3.1.3 Define ExecutionStep

 Add model:

class ExecutionStep(Base):
    __tablename__ = "execution_steps"

    id = Column(Integer, primary_key=True)
    run_id = Column(Integer, ForeignKey("execution_runs.id"), nullable=False)
    order_index = Column(Integer, nullable=False)

    actor = Column(String, nullable=False)  # "manager", "code_worker", "test_worker", "doc_worker"
    tool = Column(String, nullable=False)   # read_file, write_file, run_terminal, search_docs, search_messages, plan_only

    input_payload = Column(JSON, nullable=False)
    output_payload = Column(JSON, nullable=True)

    rollback_data = Column(JSON, nullable=True)  # e.g. { "path": "...", "original_content": "..." }

    status = Column(
        String,
        default="pending"
    )  # pending, running, completed, failed, needs_approval, skipped

    error_message = Column(Text, nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    started_at = Column(DateTime, nullable=True)
    finished_at = Column(DateTime, nullable=True)

    run = relationship("ExecutionRun", back_populates="steps")


 Add index ix_execution_steps_run_order = Index(..., "run_id", "order_index").

3.1.4 Project‑level concurrency knobs

 Extend Project with:

max_parallel_runs = Column(Integer, default=1)


(This will be used heavily in Phase 4’s manager; for now just add it.)

 Make sure any existing Pydantic Project schemas surface these fields appropriately in API responses if needed. 

DEV_GUIDE

3.2 Backend: run orchestration service

File: backend/app/services/runs.py (new module)

Define a small orchestration layer so the API endpoints don’t become huge.

3.2.1 Create helper functions

 create_run(project_id, conversation_id, task_id, run_type, started_by) -> ExecutionRun

Create and persist ExecutionRun with status "planned".

Set created_at, updated_at.

Don’t create any steps yet.

 append_step(run: ExecutionRun, *, actor, tool, input_payload, status="pending") -> ExecutionStep

Set order_index as len(run.steps).

Persist step.

 get_next_pending_step(run: ExecutionRun) -> Optional[ExecutionStep]

Return lowest order_index step with status "pending".

 mark_step_status(step, status, error_message=None, output_payload=None)

Update fields and timestamps.

 mark_run_status(run, status, error_message=None)

Update status, error_message, finished_at etc.

3.2.2 Rollback helper

 rollback_run(run_id: int) -> dict

Load run + steps ordered descending by order_index.

For each step:

If rollback_data has { "path": ..., "original_content": ... }:

Call internal file write helper to restore original content (respecting local_root_path guardrails). 

SYSTEM_OVERVIEW

Mark run status "aborted" and set error_message="Rolled back by user".

Return a summary dict for the API.

3.3 Backend: LLM tool‑calling & worker wrappers

File: backend/app/llm/openai_client.py and new backend/app/services/workers.py

3.3.1 Define tool schemas

In openai_client.py:

 Add Python definitions (e.g. dicts) describing tools:

read_file(path: str)

write_file(path: str, new_content: str)

run_terminal(command: str, cwd: str)

search_docs(query: str)

search_messages(query: str)

 Each tool maps 1:1 onto existing API or internal helpers:

GET /projects/{id}/files/content → read_file 

API_REFERENCE

POST /projects/{id}/files/apply_edit → write_file

POST /projects/{id}/terminal/run → run_terminal

POST /search/docs, /search/messages → search tools 

API_REFERENCE

3.3.2 Implement run_agent_with_tools

 Add function:

def run_agent_with_tools(agent_config, context_bundle, tools, run: ExecutionRun) -> None:
    """
    Drives a single LLM tool-calling session to execute one or more ExecutionStep(s).
    """


Behavior:

Build messages from:

Agent system prompt (role: system).

Project instructions + snapshot + plan/task snippet from ContextBundle.

Current task context if linked.

Attach tool definitions.

In a loop:

Call model with tool_choice="auto".

For each tool call from the model:

Map to backend function.

Create an ExecutionStep (if not already present) or fill one if pre‑planned.

Fill input_payload and output_payload.

Stop when:

Model returns a normal message indicating “done”, or

You hit a safety boundary (e.g., attempted forbidden command).

Ensure every executed tool call is also persisted as an ExecutionStep.

3.3.3 Worker roles module

File: backend/app/services/workers.py (new)

 Implement get_code_worker_prompt, get_test_worker_prompt, get_doc_worker_prompt.

 Implement thin wrappers:

def run_code_worker_for_step(step: ExecutionStep, context_bundle: ContextBundle) -> ExecutionStep: ...
def run_test_worker_for_step(step: ExecutionStep, context_bundle: ContextBundle) -> ExecutionStep: ...
def run_doc_worker_for_step(step: ExecutionStep, context_bundle: ContextBundle) -> ExecutionStep: ...


Each wrapper:

Builds an appropriate system prompt (role).

Calls run_agent_with_tools with allowed tools for that worker.

Updates ExecutionStep.status, output_payload, error_message.

3.4 Backend: HTTP APIs for runs & steps

File: backend/app/api/main.py + maybe routes_runs.py

Update docs/API_REFERENCE.md afterwards.

3.4.1 Pydantic schemas

 ExecutionRunCreateRequest:

conversation_id: Optional[int]

task_id: Optional[int]

run_type: str

started_by: Literal["user", "manager"]

 ExecutionRunResponse:

Basic fields of run, plus a minimal summary of steps (or separate ExecutionStepResponse).

 RunAdvanceRequest:

approval: Literal["approve", "skip", "abort"]

 RollbackRunResponse: summary fields.

3.4.2 Endpoints

 POST /projects/{project_id}/runs

Validate project existence and that task_id (if given) belongs to the project.

Call create_run.

Return ExecutionRunResponse.

 GET /projects/{project_id}/runs?status=open|all

Filter by project_id.

If status=open, include runs with status in (planned, running, awaiting_approval).

Return list of ExecutionRunResponse.

 GET /runs/{run_id}

Fetch run + steps.

Return run + full step list.

 POST /runs/{run_id}/advance

Body: RunAdvanceRequest.

If approval="abort":

Mark run as aborted via mark_run_status.

Else:

Find next pending or needs_approval step.

If approval="skip", mark step skipped.

If approval="approve", call appropriate worker wrapper to execute the step (code/test/doc), then update step and maybe run status.

Return updated run.

 POST /runs/{run_id}/rollback

Call rollback_run.

Return summary.

3.5 Backend: integrate runs with usage telemetry

File: backend/app/db/models.py and app/api/main.py

 Ensure UsageRecord (or equivalent model) has optional execution_run_id.

 Modify worker LLM calls to attach execution_run_id for any usage they generate.

 In Usage tab backend aggregation, include optional filter “group by run” (Phase 5 can surface it in UI).

3.6 Frontend: Runs panel & step UI

File: frontend/src/App.tsx (later factor out into RunsPanel.tsx)

3.6.1 Type definitions

 Add TS interfaces:

interface ExecutionRun {
  id: number;
  project_id: number;
  task_id?: number;
  run_type: string;
  status: "planned" | "running" | "awaiting_approval" | "completed" | "failed" | "aborted";
  started_by: "user" | "manager";
  created_at: string;
  updated_at: string;
  error_message?: string;
}

interface ExecutionStep {
  id: number;
  run_id: number;
  order_index: number;
  actor: string;
  tool: string;
  input_payload: any;
  output_payload?: any;
  status: "pending" | "running" | "completed" | "failed" | "needs_approval" | "skipped";
  error_message?: string;
}


3.6.2 Data fetching hooks

 Add useRuns(projectId) hook or equivalent logic:

Fetch GET /projects/{id}/runs?status=open on mount & when refreshed.

Store runs in state.

 Add useRunDetail(runId) or conditional fetch when a run is selected:

Fetch GET /runs/{runId} and store steps.

3.6.3 Runs UI

Decide positioning:

Option A: new right‑column tab “Runs”.

Option B: panel in Terminal tab.

For clarity, let’s assume new tab:

 Add “Runs” button to right‑tab toolbar and a corresponding panel component.

 In Runs panel:

Top: list of runs (table) with columns:

Status badge.

Type.

Linked task (with “View in Tasks” button).

Created_at.

When a run is selected:

Show step list:

order_index, actor, tool, status.

Short description derived from input_payload.

If output_payload.alignment exists, show alignment badge (added in Phase 2 alignment helper).

For steps with status="needs_approval":

Show “Approve” / “Skip” buttons calling POST /runs/{id}/advance.

3.6.4 Diff viewer integration

 For steps with tool="write_file":

If output_payload has before/after or diff, show “View diff”.

Render a simple side‑by‑side or inline diff inside the panel.

Provide “Open file in Files tab” button to jump to Files tab and preload that path.

3.6.5 Run creation entry point (manual)

Phase 3 is still mostly manual / “suggest mode”, so:

 In Tasks tab:

Add “Start guided run” button per task.

This button calls POST /projects/{id}/runs with:

task_id and run_type="implement_feature".

started_by="user".

Then automatically open Runs tab and select this new run.

3.7 QA for Phase 3

Backend smoke probe

 Add qa/runs_probe.py:

Create dummy project + task.

Call POST /projects/{id}/runs.

Add a single synthetic step that writes a trivial file (maybe using a fake worker, or simpler: step with tool plan_only).

If you want to fully exercise I/O:

Use code worker to write scratch/phase3_probe.txt with content "hello phase3".

Assert run lifecycle transitions planned -> running -> completed.

Docs

 Update docs/SYSTEM_MATRIX.md with ExecutionRun/Step ↔ endpoints ↔ Runs tab ↔ QA probe mapping.

 Update docs/API_REFERENCE.md with new run endpoints. 

Presentation_Outline

 Add Phase 3 checklist item to docs/TODO_CHECKLIST.md and log progress in docs/PROGRESS.md.

Phase 4 – Manager Agent, Autonomy Modes, Autopilot (ultra‑granular)

Goal: turn runs into something that a manager agent can create and advance without you micromanaging prompts, with explicit autonomy levels and an autopilot heartbeat.

4.0 Preconditions

 Phase 3 runs + workers in place, with manual “Start guided run” working end‑to‑end.

 Context builder & snapshot from Phase 2 implemented (so manager has stable project context).

4.1 Backend: Project autonomy fields

File: backend/app/db/models.py

 Extend Project:

autonomy_mode = Column(String, default="off")  # off, suggest, semi_auto, full_auto
active_phase_node_id = Column(Integer, ForeignKey("plan_nodes.id"), nullable=True)
autopilot_paused = Column(Boolean, default=False)


 Add relationship active_phase_node = relationship("PlanNode") if PlanNode model already exists.

 Update any Project Pydantic schemas to include these fields (read‑only or writable as appropriate).

4.2 Backend: Intent classifier

File: backend/app/llm/intent_classifier.py (new)

 Implement function:

def classify_intent(project_name: str, snapshot_snippet: str, last_messages: list[str], new_message: str) -> dict:
    """
    Returns {"intent": ..., "confidence": float, "notes": str}
    """


Behavior:

Build a short prompt with:

Project name.

One‑line goals from snapshot.

Last 2–3 messages (user/assistant).

Latest user message.

Ask for JSON with:

intent ∈ {QUESTION, START_BUILD, CONTINUE_BUILD, PAUSE_AUTOPILOT, ADJUST_PLAN, UPDATE_REQUIREMENTS, OTHER}

confidence (0–1)

notes (short natural language note)

Use mode="fast" model from your LLM client.

Chat endpoint integration

File: backend/app/api/main.py

Inside the chat handler, before calling generate_reply_from_history:

 Load ProjectSnapshot (or small snippet) and last few messages.

 Call classify_intent.

 If confidence < 0.6 → treat as QUESTION.

 If intent != QUESTION:

Instantiate ManagerAgent (below) and call appropriate handler (handle_start_build, handle_continue_build, etc.) in addition to normal chat reply.

For PAUSE_AUTOPILOT, set project.autopilot_paused=True.

4.3 Backend: ManagerAgent implementation

File: backend/app/services/manager.py (new)

4.3.1 Class skeleton

 Define:

class ManagerAgent:
    def __init__(self, project_id: int, session: Session):
        self.project_id = project_id
        self.session = session
        self.project = ...
        self.snapshot = ...
        self.active_blueprint = ...
        self.plan_nodes = ...
        self.tasks = ...
        self.runs = ...


 Provide helper methods to load:

Active phase PlanNode subtree.

Open tasks linked to that subtree.

Open runs (status running/awaiting_approval/planned).

4.3.2 Task selection heuristics

 Implement get_candidate_tasks():

Filter tasks:

status == "open".

source_plan_node_id in active phase subtree.

All TaskDependency dependencies are status="done".

Sort by:

PlanNode.priority (high before normal).

Task size estimate from metadata (small first).

PlanNode.order_index.

 Implement choose_next_task() returning the top candidate or None.

4.3.3 Starting runs

 Implement start_run_for_task(task: Task) -> ExecutionRun:

Create ExecutionRun with:

run_type="implement_feature" (or based on task metadata).

started_by="manager".

Ask code worker for a step plan without tools:

“Describe the steps you will take as JSON, but don’t call tools.”

Parse JSON and create ExecutionSteps with tool and input_payload placeholders, status="pending".

Set run status "planned".

 Implement should_start_new_run():

Count open runs (planned, running, awaiting_approval).

Compare to Project.max_parallel_runs.

Return True if below threshold and there is at least 1 candidate task.

4.3.4 Advancing runs

 Implement advance_run():

Pick a run:

Prefer running, else planned.

Get its next pending step via get_next_pending_step.

Use autonomy mode to decide:

off: this should never be called (guard in /autopilot_tick).

suggest: mark step needs_approval and return summary.

semi_auto:

If step.tool is safe (read/search/run tests) → execute.

Else → mark needs_approval.

full_auto:

Execute step as long as:

Terminal command is in safe allowlist (see 4.5).

Alignment check doesn’t return “conflicting”.

Execution:

Build ContextBundle for this task & run.

Dispatch to worker (run_code_worker_for_step, etc.).

Update step status (completed/failed).

Update run status accordingly.

When all steps completed:

Optionally run test_worker step if not included.

If tests pass:

Mark linked Task status="done".

Update PlanNode summary / status.

Add a Decision entry summarizing this implementation (optional).

4.3.5 Manager intent handlers

 handle_start_build(conversation_id, notes):

If project.active_phase_node_id is null:

Set it to first phase PlanNode in active blueprint.

Optionally record a Decision “Build started for Phase X”.

Optionally generate a short plan summary for logs.

 handle_continue_build(conversation_id, notes):

You can keep this simple: maybe just mark an internal flag or log; autopilot will actually do the work via ticks.

 explain_plan() -> dict:

Return:

Active phase title.

Top N recommended tasks and reasons.

Current runs and status.

This will back the “Explain current plan” endpoint/UI in Phase 5.

4.4 Backend: Autopilot tick endpoint

File: backend/app/api/main.py

 Add endpoint:

@app.post("/projects/{project_id}/autopilot_tick")
def autopilot_tick(project_id: int, session: Session = Depends(get_session)):
    project = session.get(Project, project_id)
    if not project:
        raise HTTPException(404, "Project not found")

    if project.autonomy_mode == "off" or project.autopilot_paused:
        return {"status": "idle"}

    mgr = ManagerAgent(project_id, session)

    if mgr.has_run_awaiting_approval():
        return {"status": "waiting_for_approval"}

    if mgr.has_unfinished_run():
        action = mgr.advance_run()
        return {"status": "advanced_run", "details": action}

    if mgr.should_start_new_run():
        run = mgr.start_run_for_next_task()
        return {"status": "started_run", "run_id": run.id}

    return {"status": "nothing_to_do"}


 Implement ManagerAgent.has_run_awaiting_approval and has_unfinished_run to query DB.

4.5 Backend: command allowlist & alignment gating

File: backend/app/services/workers.py or a shared safety.py

4.5.1 Command allowlist

 Define:

SAFE_COMMAND_PREFIXES = [
    "pytest",
    "python -m pytest",
    "npm test",
    "npm run build",
    "npm run lint",
    "python -m qa.run_smoke",
]
FORBIDDEN_SUBSTRINGS = [" rm ", " del ", " format ", " shutdown", " reboot", " git push"]


 When executing run_terminal in worker/autopilot context:

If command includes any FORBIDDEN_SUBSTRINGS → mark step needs_approval + add warning.

If command doesn’t start with safe prefix AND autonomy_mode != "off" → needs_approval unless user explicitly approved this step.

4.5.2 Alignment integration

Assuming Phase 2 created check_alignment(project_id, action_type, action_payload):

 For each write_file or risky run_terminal step:

Summarize the change or command (worker describes what it will do).

Call check_alignment.

Attach result under ExecutionStep.output_payload["alignment"].

 For alignment.status == "conflicting":

In semi_auto/full_auto:

Do not execute automatically even if safe.

Mark needs_approval with reason.

4.6 Frontend: Autopilot controls & heartbeat

File: frontend/src/App.tsx

4.6.1 Autonomy mode UI

 In header (near project selector), add:

Dropdown for Autopilot: Off / Suggest / Semi auto / Full auto.

This calls PATCH /projects/{id} to update autonomy_mode.

 Add “Pause / Resume autopilot” toggle bound to autopilot_paused.

 Add small status pill, e.g.:

Grey: Off.

Blue: Suggest.

Yellow: Semi.

Green: Full.

Red: Error / waiting for approval.

4.6.2 Heartbeat polling

 When:

A project is selected,

autonomy_mode != "off",

autopilot_paused == false,
start a setInterval (e.g. 30s):

useEffect(() => {
  if (!projectId || autonomyMode === "off" || autopilotPaused) return;

  let cancelled = false;
  const tick = () => {
    fetch(`/projects/${projectId}/autopilot_tick`, { method: "POST" })
      .then(r => r.json())
      .then(status => {
        if (cancelled) return;
        setAutopilotStatus(status);
        // optionally refresh runs list on started/advanced
      })
      .catch(err => setAutopilotStatus({ status: "error", error: String(err) }));
  };

  const handle = setInterval(tick, 30000);
  tick(); // initial
  return () => {
    cancelled = true;
    clearInterval(handle);
  };
}, [projectId, autonomyMode, autopilotPaused]);


 When status is started_run or advanced_run, refresh Runs panel.

 When status == "waiting_for_approval", highlight Runs tab (badge).

4.6.3 “Explain manager plan” button

 Add endpoint GET /projects/{id}/manager/plan that calls ManagerAgent.explain_plan.

 In Notes or Tasks tab, add button “Ask manager to explain current plan”.

On click, fetch plan explanation and render:

Active phase.

Next recommended tasks.

Active runs.

4.7 QA & docs for Phase 4

Backend QA

 Add qa/autopilot_probe.py:

Create a minimal project + blueprint + plan with a tiny feature (e.g. “write hello file”).

Create an open task for that PlanNode.

Set Project.autonomy_mode = "semi_auto".

Hit /autopilot_tick a few times:

Assert that a run is created.

Assert that at least one step moves to needs_approval.

Do not actually run code worker in this probe if you want it to be fully deterministic; you can stub it or keep it minimal.

Manual QA scenarios to add to docs/TEST_PLAN.md:

Turn on Suggest mode:

Confirm autopilot proposes runs but doesn’t execute steps.

Turn on Semi auto:

Confirm safe steps auto‑run and writes require approval.

Turn on Full auto in a small sandbox project:

Confirm it won’t run forbidden commands.

Confirm you can revert a run via the UI.

Docs

 Update:

docs/SYSTEM_OVERVIEW.md with a high‑level description of the manager/autopilot subsystem. 

DEV_GUIDE

docs/SYSTEM_MATRIX.md with:

ManagerAgent, intent classifier, runs, autopilot endpoints. 

API_REFERENCE

docs/API_REFERENCE.md with:

/projects/{id}/autonomy_mode (if separate), /projects/{id}/autopilot_tick, /projects/{id}/manager/plan. 

Presentation_Outline

docs/USER_MANUAL.md with:

“How to use Autopilot” plus safety notes for non‑technical users. 

USER_MANUAL

docs/AGENT_GUIDE.md with:

New safe‑ops expectations for workers and manager.

docs/DEV_GUIDE.md with:

Where ManagerAgent and workers live and how to extend them. 

DEV_GUIDE

 Log completion of Phase 3 & 4 milestones in docs/PROGRESS.md and tick off items in docs/TODO_CHECKLIST.md.