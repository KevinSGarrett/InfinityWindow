ARCHIVED: Pre‑Autopilot‑v2 design doc. Kept for historical context; see `docs/SYSTEM_OVERVIEW.md`, `docs/SYSTEM_MATRIX.md`, `docs/AUTOPILOT_PLAN.md`, `docs/TODO_CHECKLIST.md`, and `docs/PROGRESS.md` for the current state of the system.

This file gives concrete, end‑to‑end examples of how to use the autopilot manager + worker system once it is implemented, from “CEO mode” down to individual runs.

These examples assume:

The Blueprint / Plan / Task graph features are in place.

ExecutionRun / ExecutionStep + workers exist.

ManagerAgent + autopilot modes are implemented and wired into the UI.

1. Example: Bootstrapping a new project from a huge blueprint

Goal: Turn a 500k‑word project spec into a living plan, then let autopilot start building the MVP in suggest/semi‑auto mode.

Preconditions

A new InfinityWindow project exists with:

local_root_path pointing at the target repo (possibly empty or skeleton).

API_REFERENCE

Backend and frontend are running.

The blueprint spec is available as a text/Markdown file.

Steps

Upload and ingest the blueprint

Go to Docs tab → “Ingest text doc”.

Name it “Master Blueprint v1”.

Paste or upload the full spec.

Save.

Create a Blueprint and generate a Plan

Open Tasks tab → Blueprint/Plan section.

Click “Create blueprint from doc” and select “Master Blueprint v1”.

After creation, click “Generate plan”.

Wait for PlanNodes (phases → epics → features → stories) to appear in the tree.

Decompose features into tasks

Expand Phase 1 – MVP → pick an epic (e.g. “Auth & Onboarding”).

For each feature node (e.g. “User registration”), click “Generate tasks”.

Review and lightly edit tasks (titles, acceptance criteria, risk/priority).

Set up autopilot

In the project header or Notes tab:

Set Autonomy: suggest (first run).

Set Active phase: “Phase 1 – MVP”.

Save project instructions summarizing:

Tech stack.

Non‑negotiable constraints.

QA expectations.

DEV_GUIDE

Tell the manager to start

In Chat:

“Use the Master Blueprint v1 to build the MVP. Start with the auth phase.”

The intent classifier tags this as START_BUILD; ManagerAgent:

Confirms active phase.

Picks the top unblocked task under “Auth & Onboarding”.

Creates a planned ExecutionRun.

Review proposed runs

In Runs panel:

See Run #1: “Implement user registration API”.

Inspect its steps (plan, read files, write implementation, add tests, run tests).

Approve the run in suggest mode to allow workers to begin.

Iterate

Let autopilot complete one or two small features.

Once confident:

Switch Autonomy to semi_auto so safe steps (reads/tests) run automatically.

2. Example: Implementing a single feature in semi_auto

Goal: Autopilot implements a specific feature end‑to‑end, while you approve file edits and unsafe commands.

Scenario

You want to implement “User registration API” under the Auth epic.

Steps

Pick the feature

In the Plan tree, select PlanNode “User registration”.

Ensure tasks were generated (e.g. “Design DB schema for users”, “Implement /api/register”, “Write tests for registration”).

Ask the manager to focus on it

In Chat:

“Start work on the ‘User registration API’ feature and get it to passing tests in semi_auto mode.”

Manager:

Validates tasks under that PlanNode.

Creates a run for the first task (schema) and another for the implementation, respecting dependencies.

Watch runs progress

In Runs panel:

Run #3: “Design user schema”.

Run #4: “Implement registration endpoint”.

Approve edits

When a run hits a write step:

Review diff for models/user.py / app/api/auth.py.

Check alignment badge (“Aligned with Phase 1 / Auth”).

Click “Approve step”.

Tests

Test worker runs pytest for the new tests.

If tests fail:

Autopilot loops:

Reads failing test output.

Proposes targeted code/test edits.

Re‑runs tests.

You approve file edits as needed.

Completion

When tests are green:

Run status → completed.

Task(s) linked to the PlanNode mark done.

Manager updates snapshot:

“User registration API implemented and tested”.

3. Example: CEO mode for a non‑developer

Goal: A non‑technical user guides a multi‑week project mainly through chat, while autopilot does the dev work inside guardrails.

Setup

Blueprint, Plan, and initial tasks are in place.

Basic CI (smoke tests, unit tests) exist.

Autonomy is set to semi_auto or full_auto depending on trust.

Pattern

High‑level instructions only

User messages are very high level:

“This week, focus on payment flows.”

“Deprioritize marketing site work for now.”

“Once auth and billing are done, we’ll think about reporting.”

Manager makes sense of it

Autopilot interprets these as:

Updates to active phase.

Reprioritization of PlanNodes/tasks (e.g., payment features first).

It chooses tasks and runs that fit these priorities.

Human interaction points

The CEO user:

Approves or rejects diffs at a conceptual level (“Yes, that’s how I want payment retries to work.”).

Asks the manager for explanations:

“Explain what changed in the last 3 runs in simple terms.”

“Summarize what we got done this week.”

Snapshots for sanity

The Project Snapshot doc becomes the CEO’s “status report”:

Goals, completed work, risks, next steps.

The CEO can ask:

“If we need to ship an MVP in 2 weeks, what should we drop?”
→ Manager suggests PlanNodes to de‑scope and tasks to defer.

This example highlights that the CEO doesn’t need to know which worker is doing what – they just nudge directions and approve major decisions.

4. Example: Handling a failing run

Goal: Show how autopilot fails safely and how you recover when something goes wrong.

Scenario

Autopilot is implementing a refactor. A run introduces failing tests that the worker can’t fix automatically.

Steps

Failure happens

Run #9 status → failed.

The last step has:

status="failed".

error_message with traceback or test failure summary.

The Runs panel highlights the run in red.

Autopilot behavior

Manager:

Stops advancing this run.

Does not start new dependent tasks.

Surfaces a summary in chat:

“Refactor run #9 failed while updating payment handler X. Tests Y and Z are failing with [reason].”

Human options

You can:

Open diffs for the failing step.

Ask chat:

“Explain the failure in non‑technical terms.”

“Suggest how to fix this without changing behavior.”

Decide:

a. Fix & continue

Approve a minimal fix patch proposed by code worker.

Click “Retry step” or “Continue run” (depending on UI).

Tests re‑run; if green, run moves to completed.

b. Roll back

Click “Revert run”.

All files touched by run #9 are returned to their pre‑run state.

Manager logs a Decision:

“Refactor X aborted; design needs revisiting.”

Post‑mortem

Optionally:

Log a Decision for why the refactor failed.

Create tasks for a more careful redesign.

This example shows autopilot is allowed to fail but must fail in a way that is inspectable and reversible, not silently corrupting the project.

5. Example: Updating the blueprint mid‑project

Goal: Adjust the plan when requirements change, without losing all progress.

Scenario

Mid‑project, the product owner delivers a new version of the blueprint that changes the onboarding flow and billing rules.

Steps

Ingest new blueprint version

In Docs:

Ingest “Master Blueprint v2”.

In Tasks / Blueprint section:

Create a new Blueprint linked to v2.

Run “Generate plan” for v2.

Compare v1 and v2

Use a “Compare to parent” action or manual review:

PlanNodes that changed are marked changed=true in metadata.

Each changed node gets a short change_note.

Tell the manager to reconcile

In Chat:

“We have a new blueprint version. Update the plan and tasks so we match v2, but keep already‑implemented features unless they explicitly changed.”

Manager:

For each changed PlanNode:

Creates new tasks or updates existing ones.

Marks some old tasks as obsolete.

Leaves already completed runs alone unless v2 explicitly contradicts them.

Autopilot resumes

Active phase may remain the same (Phase 1 – MVP).

Manager picks next tasks based on updated PlanNodes.

The key takeaway: autopilot treats blueprints as versioned truth, not immutable scripture. You can change direction mid‑stream without throwing away all prior work.

6. Example: Using autopilot just for testing & QA

Goal: Use autopilot as a smart test runner and fixer, even if you don’t fully trust it to implement features.

Scenario

You want to keep writing code manually but let autopilot:

Run tests frequently.

Interpret failures.

Propose small fixes.

Steps

Set Autonomy to semi_auto

Instructions:

Note that autopilot should not implement new features by itself.

Emphasize “focus on test running + small bug fixes”.

Manual coding, autopilot for tests

You edit files in Files tab or your local editor.

In Chat:

“Run tests for backend and help me fix any failures.”

Autopilot behavior

Manager:

Starts a run_tests_only run.

Test worker:

Runs pytest + other safe commands.

Summarizes failures.

Fix cycle

For each failure:

Code worker suggests minimal patches.

You review diffs and approve or reject.

Repeat until tests pass.

This gives you a “smart QA assistant” even if you don’t want full feature‑building automation yet.

7. Where this fits in the broader system

Autopilot examples sit on top of InfinityWindow’s existing capabilities:

Projects with conversations, tasks, docs, memory, files, terminal, usage.

API_REFERENCE

Right‑hand workbench tabs for Tasks/Docs/Files/Search/Terminal/Usage/Notes/Memory.

AGENT_GUIDE

Operations runbooks and QA flows (qa/run_smoke.py, Playwright tests, make ci in QA).

OPERATIONS_RUNBOOK

Treat this file as the playbook of real workflows once the autopilot manager + workers are implemented. When you extend the system with new run types, worker roles, or autonomy modes, add at least one new example here so humans and agents can see how it’s meant to be used.