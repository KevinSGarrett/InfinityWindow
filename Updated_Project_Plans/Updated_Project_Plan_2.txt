Current design spec for Autopilot / Blueprint / Learning & ingestion phases as of 2025-12-09.
Implementation status is tracked in docs/REQUIREMENTS_CRM.md, docs/TODO_CHECKLIST.md, and docs/PROGRESS.md. Autopilot remains design-only; these documents are roadmap/spec, not shipped behavior.

0. Goals, assumptions, safety contract
0.1 What we’re building

We’re extending InfinityWindow into:

Blueprint & Plan Graph

Ingest huge blueprints (up to ~500k words) as first‑class Blueprints.

Derive a hierarchical Plan tree (phases → epics → features → stories → task specs).

Generate executable Tasks from that tree and keep everything linked.

Project Brain & Long‑Term Alignment

Conversation summaries + Project Snapshot doc per project.

Deterministic ContextBuilder that always gives the model the right slice of state.

Alignment checks so file edits/commands are checked against plan + decisions.

Execution Runs & Worker Agents

ExecutionRun / ExecutionStep models for multi‑step automations.

Tool‑calling workers over Files + Terminal + Search, wired to existing endpoints.

Manager Agent & Autopilot

Project‑level autonomy modes: off, suggest, semi_auto, full_auto.

Intent detection on each user message (START_BUILD, PAUSE_AUTOPILOT, etc.).

/projects/{id}/autopilot_tick heartbeat: manager advances runs and starts new ones.

Target automation level: “CEO + auto‑PM + dev team”. You upload a 500k‑word blueprint, tell the system “Start building Phase 1”, and the manager:

Turns the blueprint into a plan + tasks.

Chooses build order.

Spawns code/test/doc workers.

Edits files, runs tests, updates tasks — within guardrails.

You mostly approve & steer, plus deep‑dive with chat when needed.

0.2 Assumptions about the existing system

We assume the current state:

FastAPI backend with Project, Conversation, Message, Task, Document, MemoryItem, Decision, usage models. 

HYDRATION_2025-12-02

React/Vite frontend with 3‑column layout and 8 right‑hand tabs (Tasks, Docs, Files, Search, Terminal, Usage, Notes, Memory).

Filesystem + Terminal endpoints scoped to Project.local_root_path.

LLM client with modes (auto, fast, deep, budget, research, code) and telemetry.

Docs that describe this: SYSTEM_OVERVIEW.md, SYSTEM_MATRIX.md, USER_MANUAL.md, API_REFERENCE.md.

0.3 Non‑goals (for this plan)

We’re not designing CI/CD or deployment pipelines.

We’re not rebuilding the UI layout; we’re adding panels and controls into the existing layout.

We’re not implementing external web search yet (that can be layered later as a new tool).

0.4 Safety contract for agents

Reinforce the repo’s existing agent safety rules:

Filesystem safety

All file operations go through existing filesystem endpoints and are confined to local_root_path.

Path normalization must prevent escaping the project root (.., symlinks, etc.).

Terminal safety

All terminal commands go through /projects/{id}/terminal/run.

Autopilot only auto‑executes commands from a strict allowlist (tests, lints, builds).

Destructive commands (rm, del, git push, format, shutdown, etc.) are never auto‑run.

Human‑in‑the‑loop

In suggest and semi_auto modes, all file writes and unsafe commands require explicit approval in the UI.

In full_auto, only allow auto‑writes within project root, with rollback available.

Docs sync & QA discipline

After adding these features, docs (SYSTEM_MATRIX, API_REFERENCE, DEV_GUIDE, USER_MANUAL, OPERATIONS_RUNBOOK, TEST_PLAN) must be updated.

1. Phase 1 – Blueprint & Plan Graph
1.1 Data models

File: backend/app/db/models.py

Add:

PLAN_NODE_KIND = ("phase", "epic", "feature", "story", "task_spec")
BLUEPRINT_STATUS = ("draft", "active", "archived")

class Blueprint(Base):
    __tablename__ = "blueprints"

    id = Column(Integer, primary_key=True)
    project_id = Column(Integer, ForeignKey("projects.id"), nullable=False)
    document_id = Column(Integer, ForeignKey("documents.id"), nullable=False)

    title = Column(String, nullable=False)
    description = Column(String, nullable=True)
    status = Column(String, default="active")  # draft, active, archived

    version = Column(Integer, default=1)
    is_primary = Column(Boolean, default=True)
    parent_blueprint_id = Column(Integer, ForeignKey("blueprints.id"), nullable=True)
    replaced_by_id = Column(Integer, ForeignKey("blueprints.id"), nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    project = relationship("Project", back_populates="blueprints")
    document = relationship("Document")
    parent_blueprint = relationship("Blueprint", remote_side=[id], foreign_keys=[parent_blueprint_id])
    replaced_by = relationship("Blueprint", remote_side=[id], foreign_keys=[replaced_by_id])
    plan_nodes = relationship("PlanNode", back_populates="blueprint")

class PlanNode(Base):
    __tablename__ = "plan_nodes"

    id = Column(Integer, primary_key=True)
    blueprint_id = Column(Integer, ForeignKey("blueprints.id"), nullable=False)
    parent_id = Column(Integer, ForeignKey("plan_nodes.id"), nullable=True)

    kind = Column(String, nullable=False)    # phase, epic, feature, story, task_spec
    title = Column(String, nullable=False)
    summary = Column(Text, nullable=True)

    doc_anchor = Column(String, nullable=True)
    start_offset = Column(Integer, nullable=True)
    end_offset = Column(Integer, nullable=True)

    order_index = Column(Integer, default=0)

    status = Column(String, default="planned")   # planned, in_progress, blocked, done
    priority = Column(String, default="normal")  # low, normal, high
    estimate_points = Column(Integer, nullable=True)
    risk_level = Column(String, default="normal")  # low, normal, high

    extra_metadata = Column(JSON, nullable=True)

    linked_task_id = Column(Integer, ForeignKey("tasks.id"), nullable=True)

    blueprint = relationship("Blueprint", back_populates="plan_nodes")
    parent = relationship("PlanNode", remote_side=[id])
    linked_task = relationship("Task")

    __table_args__ = (
        Index("ix_plan_nodes_blueprint_parent_order", "blueprint_id", "parent_id", "order_index"),
        Index("ix_plan_nodes_blueprint_kind", "blueprint_id", "kind"),
        Index("ix_plan_nodes_blueprint_status", "blueprint_id", "status"),
    )


For 1‑N task linkage:

class PlanNodeTaskLink(Base):
    __tablename__ = "plan_node_task_links"
    id = Column(Integer, primary_key=True)
    plan_node_id = Column(Integer, ForeignKey("plan_nodes.id"), nullable=False)
    task_id = Column(Integer, ForeignKey("tasks.id"), nullable=False)
    weight = Column(Integer, default=1)


Task dependencies:

class TaskDependency(Base):
    __tablename__ = "task_dependencies"
    id = Column(Integer, primary_key=True)
    task_id = Column(Integer, ForeignKey("tasks.id"), nullable=False)
    depends_on_task_id = Column(Integer, ForeignKey("tasks.id"), nullable=False)


Optional ingestion job tracking:

class BlueprintIngestionJob(Base):
    __tablename__ = "blueprint_ingestion_jobs"
    id = Column(Integer, primary_key=True)
    blueprint_id = Column(Integer, ForeignKey("blueprints.id"), nullable=False)
    status = Column(String, default="pending")  # pending, running, done, error
    total_chunks = Column(Integer, nullable=True)
    processed_chunks = Column(Integer, nullable=True)
    error_message = Column(Text, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


Extend Project:

class Project(Base):
    # existing fields...
    active_blueprint_id = Column(Integer, ForeignKey("blueprints.id"), nullable=True)
    # (later we also add autonomy fields in Phase 4)
    blueprints = relationship("Blueprint", back_populates="project")

1.2 Blueprint & plan endpoints

File: backend/app/api/main.py + maybe routes_blueprints.py.

Create blueprint

POST /projects/{project_id}/blueprints
Body: { "document_id": int, "title": str, "description": str | null, "base_blueprint_id": int | null }


Validates document_id belongs to the project.

If base_blueprint_id supplied:

Load base blueprint, set version = base.version + 1.

Set base.is_primary = False, base.replaced_by_id = new.id.

New blueprint: is_primary = True.

Optionally set project.active_blueprint_id if "mark_active": true.

List blueprints

GET /projects/{project_id}/blueprints


Returns all blueprints + is_primary flag.

Get blueprint + plan

GET /blueprints/{blueprint_id}


Returns:

{
  "blueprint": {...},
  "plan_tree": [ /* nested PlanNode tree */ ],
  "ingestion_job": {...} | null
}


Update blueprint

PATCH /blueprints/{blueprint_id}


Update title, description, status.

Optional "mark_active": true to set project’s active_blueprint_id.

Update PlanNode

PATCH /plan_nodes/{id}


Update title, summary, kind, status, priority, order_index, estimate_points, risk_level, extra_metadata.

Generate / refresh plan

POST /blueprints/{blueprint_id}/generate_plan
Body: { "regenerate": bool = false }


If no PlanNodes exist or regenerate=true, run ingestion pipeline (below) and create PlanNodes.

Optionally create BlueprintIngestionJob and update processed_chunks as you go.

Compare blueprint to parent (later / optional)

POST /blueprints/{id}/compare_to_parent


For future: mark nodes as changed in extra_metadata by comparing titles/anchors with parent blueprint.

1.3 Ingestion pipeline: 500k‑word doc → PlanNode tree

File: backend/app/services/blueprints.py (new). 

DEV_GUIDE

Steps:

Load document

Fetch Document by document_id. Use its full content.

Chunking

Reuse your existing document ingestion chunk logic used for /docs/text and Chroma ingestion.

Track start_offset / end_offset char indices per chunk and chunk_index.

Per‑chunk outline extraction

For each chunk, call LLM (mode "deep" or "research") with a prompt like:

“You are turning a huge project blueprint into a build plan.
For this text fragment, extract any logical sections and classify them as phase, epic, feature, or story. Return only JSON…”

Output example:

[
  {
    "kind": "phase",
    "title": "MVP",
    "summary": "...",
    "anchor": "3. MVP",
    "children": [
      {
        "kind": "epic",
        "title": "Authentication",
        "summary": "...",
        "anchor": "3.1 Authentication",
        "children": [...]
      }
    ]
  }
]


Global outline merge

Combine partial outlines into a global tree via a second LLM call:

Deduplicate similar titles (e.g., "MVP" / "MVP Phase").

Enforce strict tree: phases → epics → features → stories.

Attach approximate start_offset/end_offset ranges based on chunk indices.

Assign order_index in reading order.

Create PlanNodes

Traverse merged tree and insert PlanNodes:

kind from node kind.

title, summary.

doc_anchor from anchor.

offsets from aggregated chunk offsets.

order_index sequential within siblings.

Error handling

If LLM JSON invalid:

Retry once with a stricter prompt (“Return JSON only; no explanation.”).

On second failure, set BlueprintIngestionJob.status="error" and store error_message.

Return 400 with a clear message.

1.4 PlanNode → Tasks (with dependencies)

File: backend/app/services/blueprints.py (same module).

Helper:

def generate_tasks_for_plan_node(plan_node_id: int):
    ...


Steps:

Fetch PlanNode + Blueprint + Document content slice:

Use start_offset/end_offset if available; otherwise, find heading text in the doc.

Call LLM (mode "code" or "deep") with prompt like:

“You are a senior project manager and tech lead.
Given this feature/story spec, produce a JSON array of tasks that fully implement it.
Each task must have: title, kind (backend, frontend, infra, docs, research, bug), acceptance_criteria (list of strings), dependencies (list of other task titles), estimated_effort (XS,S,M,L,XL), risk_level (low,medium,high).”

Parse JSON, create Task rows:

for t in tasks_json:
    task = Task(
        project_id=blueprint.project_id,
        description=t["title"],
        status="open",
        metadata_json={
            "kind": t["kind"],
            "acceptance_criteria": t["acceptance_criteria"],
            "dependencies": t.get("dependencies", []),
            "estimated_effort": t.get("estimated_effort", "M"),
            "risk_level": t.get("risk_level", "medium"),
            "source_plan_node_id": plan_node.id,
        },
    )
    session.add(task)
    session.flush()
    session.add(PlanNodeTaskLink(plan_node_id=plan_node.id, task_id=task.id))


Create TaskDependency rows:

For each task with dependencies titles:

Try to resolve dependency titles to existing tasks in the same PlanNode or parent PlanNode by normalized description.

For each match, create TaskDependency(task_id=task.id, depends_on_task_id=dep_task.id).

If unresolved, store unresolved names in metadata_json["unresolved_dependencies"] for later.

Endpoints:

POST /plan_nodes/{plan_node_id}/generate_tasks


Generates tasks only for that PlanNode.

POST /blueprints/{blueprint_id}/generate_all_tasks


Optional: loops generate_tasks_for_plan_node for all feature/story nodes (heavy on 500k docs; note this in docs).

1.5 Frontend – Blueprint & Plan view

File: frontend/src/App.tsx (later can refactor to PlanPanel.tsx).

In Tasks tab:

Blueprint selector

Dropdown Active blueprint:

Options = GET /projects/{id}/blueprints.

Shows version + status + primary flag.

“Use as active blueprint” button:

Calls PATCH /blueprints/{id} with "mark_active": true.

Plan tree view

Fetch plan via GET /blueprints/{id}.

Render nested tree:

Phase → Epic → Feature → Story.

Status chip (planned / in progress / done).

Priority chip (low/normal/high).

When clicking a node:

Show summary + doc snippet.

Buttons:

“Generate tasks for this node” → POST /plan_nodes/{id}/generate_tasks.

“Set active phase” if kind="phase" → set Project.active_phase_node_id (Phase 4).

Tasks filtering & metadata

When a PlanNode selected:

Filter task list to tasks with metadata_json.source_plan_node_id == node.id.

Show breadcrumb chip like Phase 1 / Auth / Registration.

Task rows show:

[kind] [effort] [risk] chips from metadata.

Hover tooltip listing acceptance criteria.

PlanNode status auto‑update (optional)

If a PlanNode has "auto_status_from_tasks": true in extra_metadata:

Backend cron or hooks:

When all linked tasks are done, set PlanNode.status="done".

When at least one task in progress, mark in_progress.

2. Phase 2 – Project Brain & Context Engine

Goal: every LLM call behaves like a long‑term project copilot, not a stateless chatbot.

2.1 Conversation summaries

File: backend/app/db/models.py, backend/app/api/main.py, backend/app/services/conversation_summaries.py.

Model:

class ConversationSummary(Base):
    __tablename__ = "conversation_summaries"

    id = Column(Integer, primary_key=True)
    conversation_id = Column(Integer, ForeignKey("conversations.id"), unique=True)
    short_summary = Column(Text, nullable=False)   # 3–5 sentences
    detail_summary = Column(Text, nullable=True)  # bullets of key points
    last_message_id = Column(Integer, ForeignKey("messages.id"), nullable=False)
    updated_at = Column(DateTime, default=datetime.utcnow)


Helper:

def update_conversation_summary(conversation_id: int):
    # load ConversationSummary if exists
    # fetch messages since last_message_id (or all if none)
    # call LLM (mode="fast" or "deep"):
    #   input: existing short+detail, new messages
    #   output JSON: { "short_summary": "...", "detail_summary": "..." }
    # update model


Trigger in chat endpoint:

When new messages since last summary > N (e.g., 20) or token count > threshold.

2.2 ProjectSnapshot

File: backend/app/db/models.py, backend/app/services/snapshot.py.

Model:

class ProjectSnapshot(Base):
    __tablename__ = "project_snapshots"

    id = Column(Integer, primary_key=True)
    project_id = Column(Integer, ForeignKey("projects.id"), unique=True)

    summary_text = Column(Text, nullable=False)
    active_phase_node_id = Column(Integer, ForeignKey("plan_nodes.id"), nullable=True)
    key_metrics_json = Column(JSON, nullable=True)  # {"open_tasks": ..., "runs_in_progress": ...}

    updated_at = Column(DateTime, default=datetime.utcnow)


Helper:

def refresh_project_snapshot(project_id: int):
    # load:
    #   project instructions
    #   active blueprint + active phase PlanNode
    #   top PlanNodes in active phase
    #   ConversationSummary for recent convos
    #   recent Decisions
    #   top open Tasks (by priority/unblocked)
    #   ExecutionRuns stats (in progress, failed, etc.)
    # build key_metrics_json
    # call LLM (deep) to produce structured markdown with sections:
    #   - Goals
    #   - Active phases & status
    #   - Key decisions & constraints
    #   - Top open tasks
    #   - Recent progress
    #   - Top risks / unknowns
    # upsert Document(kind="snapshot") + ProjectSnapshot


Triggers:

When more than N tasks change status since last snapshot.

When a Decision is added/updated.

When active_phase_node_id or active_blueprint_id changes.

Manual POST /projects/{id}/snapshot/refresh.

Frontend:

Docs tab: pin snapshot doc at top.

Notes tab: small snapshot card (“Active phase, open tasks count, last updated”).

2.3 ContextBuilder

File: backend/app/llm/context_builder.py.

Define:

@dataclass
class PlanNodeContext: ...
@dataclass
class TaskContext: ...
@dataclass
class DecisionContext: ...
@dataclass
class MemoryContext: ...

@dataclass
class ContextBundle:
    project_instructions: str
    pinned_note: Optional[str]
    snapshot_text: Optional[str]
    relevant_plan_nodes: List[PlanNodeContext]
    relevant_tasks: List[TaskContext]
    recent_decisions: List[DecisionContext]
    memory_items: List[MemoryContext]
    conversation_summary_short: Optional[str]
    conversation_summary_detail: Optional[str]
    recent_messages: List[Message]


Algorithm:

Always include:

Project instructions + pinned note (from Notes tab).

Snapshot summary.

Conversation short summary.

Retrieve candidates:

PlanNodes whose titles/summaries keyword‑match latest user message, plus those in active phase.

Tasks linked to those nodes.

Recent decisions matching query terms.

Memory items via vector search on message text.

Score by relevance + recency; keep within token budget (e.g., up to 5 nodes, 10 tasks, 5 decisions, 5 memories).

Attach last 5–10 raw messages.

generate_reply_from_history becomes:

ctx = build_context_for_chat(project_id, conversation_id, latest_user_message)
# build system prompt from ctx
# call LLM

2.4 Alignment helper

File: backend/app/services/alignment.py.

Input:

def check_alignment(project_id: int, action_type: str, action_payload: Dict) -> Dict:
    # action_type: "file_edit" or "terminal_command"
    # action_payload:
    #   file_edit: {"path": "...", "patch_summary": "..."}
    #   terminal_command: {"command": "...", "cwd": "...", "reason": "..."}


Steps:

Build mini context:

Snapshot.

PlanNodes whose extra_metadata.file_path matches or whose title matches path/command terms (can add file_path later).

Decisions with matching keywords.

Ask LLM:

“Given this plan, snapshot, and decisions, classify this action as aligned, risky, or conflicting. Return JSON…”

Output:

{
  "status": "aligned|risky|conflicting",
  "alignment_score": 0.0-1.0,
  "reasons": "...",
  "related_plan_nodes": [{ "id": 1, "title": "...", "kind": "feature" }],
  "related_decisions": [{ "id": 3, "title": "Use Postgres" }]
}


Usage:

For any proposed write_file or non‑safe run_terminal step, call check_alignment and:

Attach result to ExecutionStep.output_payload["alignment"].

Show badge in UI (green/yellow/red).

3. Phase 3 – Execution Runs & Worker Tools

This is the Cursor‑like multi‑step execution surface.

3.1 Models

File: backend/app/db/models.py.

class ExecutionRun(Base):
    __tablename__ = "execution_runs"

    id = Column(Integer, primary_key=True)
    project_id = Column(Integer, ForeignKey("projects.id"), nullable=False)
    conversation_id = Column(Integer, ForeignKey("conversations.id"), nullable=True)
    task_id = Column(Integer, ForeignKey("tasks.id"), nullable=True)

    run_type = Column(String, nullable=False)  # implement_feature, fix_bug, refactor_module, write_docs, run_tests_only, ...
    status = Column(String, default="planned") # planned, running, awaiting_approval, completed, failed, aborted

    started_by = Column(String, nullable=False) # "user" or "manager"
    error_message = Column(Text, nullable=True)
    meta = Column(JSON, nullable=True)  # timings, token stats, etc.
    touched_files_json = Column(JSON, nullable=True)  # {path: {"before": "...", "after": "..."}}

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    started_at = Column(DateTime, nullable=True)
    finished_at = Column(DateTime, nullable=True)

class ExecutionStep(Base):
    __tablename__ = "execution_steps"

    id = Column(Integer, primary_key=True)
    run_id = Column(Integer, ForeignKey("execution_runs.id"), nullable=False)
    order_index = Column(Integer, nullable=False)

    actor = Column(String, nullable=False)      # manager, code_worker, test_worker, doc_worker
    tool = Column(String, nullable=False)       # read_file, write_file, run_terminal, search_docs, search_messages, ...

    input_payload = Column(JSON, nullable=False)
    output_payload = Column(JSON, nullable=True)

    status = Column(String, default="pending")  # pending, running, completed, failed, needs_approval, skipped
    error_message = Column(Text, nullable=True)
    rollback_data = Column(JSON, nullable=True)  # for write_file steps: {"path": "...", "original_content": "..."}

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    started_at = Column(DateTime, nullable=True)
    finished_at = Column(DateTime, nullable=True)


Extend Project:

class Project(Base):
    # later, in Phase 4:
    autonomy_mode = Column(String, default="off")  # off, suggest, semi_auto, full_auto
    active_phase_node_id = Column(Integer, ForeignKey("plan_nodes.id"), nullable=True)
    autopilot_paused = Column(Boolean, default=False)
    max_parallel_runs = Column(Integer, default=1)


Also add execution_run_id FK to Usage model so Usage tab can group by run.

3.2 Runs API

File: backend/app/api/main.py (or routes_runs.py).

Create run

POST /projects/{project_id}/runs
Body:
{
  "conversation_id": int | null,
  "task_id": int | null,
  "run_type": "implement_feature" | "fix_bug" | "refactor_module" | "write_docs" | "run_tests_only",
  "started_by": "user" | "manager"
}


Validates project & optional task belong together.

Creates ExecutionRun with status "planned".

Get run

GET /runs/{run_id}


Returns run + ordered steps.

Advance run

POST /runs/{run_id}/advance
Body: { "approval": "approve" | "skip" | "abort" }


approve: execute next pending step via workers (see 3.4).

skip: mark step skipped, move to next.

abort: mark run aborted.

List runs

GET /projects/{project_id}/runs?status=open|all


Rollback run

POST /runs/{run_id}/rollback


For each step with rollback_data, restore original file contents.

Mark run aborted with error_message="Rolled back by user".

3.3 LLM tool schemas

File: backend/app/llm/openai_client.py.

Define tools for worker agents that map 1:1 to existing endpoints:

read_file(path: str) → GET /projects/{id}/files/content

write_file(path: str, new_content: str) → POST /projects/{id}/files/apply_edit

run_terminal(command: str, cwd: str) → POST /projects/{id}/terminal/run

search_docs(query: str) → POST /search/docs

search_messages(query: str) → POST /search/messages

Implement run_agent_with_tools(agent_config, context_bundle):

Call LLM with system prompt + context + tool definitions.

For each tool call returned:

Verify tool is allowed for this agent.

Record an ExecutionStep (status running → completed / failed / needs_approval).

Execute backend call, attach input/output/rollback_data/diff.

Stop when:

Agent emits “done” signal.

A step requires approval (write or unsafe command).

Hard safety limit reached (max steps, tokens, or error count).

3.4 Worker roles

File: backend/app/services/workers.py.

Define wrappers:

def run_code_worker(context: ContextBundle, instructions: str, tools: ToolSet) -> AgentResult: ...
def run_test_worker(context: ContextBundle, instructions: str, tools: ToolSet) -> AgentResult: ...
def run_doc_worker(context: ContextBundle, instructions: str, tools: ToolSet) -> AgentResult: ...


Prompts:

Code worker

“You are a senior software engineer on project {project_name}.
You have tools: read_file, write_file, run_terminal, search_docs, search_messages.
You must respect project instructions and decisions.
Before each tool call, briefly explain what you will do and why.
Avoid destructive operations; use only safe commands.”

Test worker

“You design and run tests for this project.
Prefer safe test commands (pytest, npm test, npm run build).
When tests fail, summarize failures and propose fixes.”

Doc worker

“You keep docs in sync with blueprint and code.
Update docs under /docs or other designated paths to reflect current behavior.”

Each worker calls run_agent_with_tools with an allowed subset of tools.

3.5 Diffs & rollback details

Before write_file:

Read original content.

Ask worker to propose new content.

Compute diff and store:

In ExecutionStep.output_payload["diff"].

In ExecutionRun.touched_files_json[path] = {"before": "...", "after": "..."}.

In ExecutionStep.rollback_data.

Apply write only after approval (unless full_auto allows auto‑write; still record rollback info).

“Revert run” uses touched_files_json to restore all affected files.

3.6 Command safety allowlist

In code:

SAFE_COMMAND_PREFIXES = [
    "pytest",
    "python -m pytest",
    "python -m qa.run_smoke",
    "npm test",
    "npm run build",
    "npm run lint",
]
FORBIDDEN_SUBSTRINGS = ["rm ", "del ", "format ", "shutdown", "reboot", "git push"]


If a worker proposes run_terminal:

If command contains any forbidden substrings → force needs_approval and mark high‑risk in alignment.

If not matching SAFE_COMMAND_PREFIXES and we’re in autopilot → needs_approval.

Terminal contract is aligned with OPERATIONS_RUNBOOK.md. 

OPERATIONS_RUNBOOK

3.7 Runs panel UX

File: frontend/src/App.tsx (or RunsPanel.tsx).

Add Runs view (either its own tab or nested under Terminal):

List of runs:

Columns: id, type, status, linked task, created_at, started_by.

Filters: by status, run_type, actor.

Run detail:

Steps table: order, actor, tool, status, alignment badge.

For write steps: “View diff” (show before/after).

Actions:

“Approve next step” → POST /runs/{id}/advance with "approve".

“Skip step” → "skip".

“Abort run”.

“Revert run” if rollback data exists.

4. Phase 4 – Manager Agent & Autopilot

Now we make it act like a project manager that decides what to do, when, and how.

4.1 Project autonomy settings

Extend Project model (as above):

autonomy_mode = Column(String, default="off")  # off, suggest, semi_auto, full_auto
active_phase_node_id = Column(Integer, ForeignKey("plan_nodes.id"), nullable=True)
autopilot_paused = Column(Boolean, default=False)
max_parallel_runs = Column(Integer, default=1)


UI (header or Notes tab):

Autopilot dropdown: Off | Suggest | Semi-auto | Full auto.

Active phase selector: PlanNode of kind phase from active blueprint.

4.2 Intent classifier

File: backend/app/llm/intent_classifier.py.

For each user message:

Build small context:

Latest message text.

Project name + short snapshot line.

Call fast model with prompt:

“Classify the primary intent as one of:
QUESTION, START_BUILD, CONTINUE_BUILD, PAUSE_AUTOPILOT, ADJUST_PLAN, UPDATE_REQUIREMENTS, OTHER.
Return JSON { "intent": "...", "confidence": 0-1, "notes": "..." }.”

Router:

If confidence < 0.6 → treat as QUESTION.

Else:

START_BUILD → ManagerAgent.handle_start_build(...).

CONTINUE_BUILD → handle_continue_build(...).

PAUSE_AUTOPILOT → set autopilot_paused = True.

ADJUST_PLAN or UPDATE_REQUIREMENTS → manager updates plan/blueprint.

4.3 ManagerAgent

File: backend/app/services/manager.py.

Skeleton:

class ManagerAgent:
    def __init__(self, project_id: int):
        self.project_id = project_id
        self.project = ...
        self.active_blueprint = ...
        self.active_phase_node = ...
        self.tasks = ...
        self.decisions = ...
        self.snapshot = ...
        # etc.

    def handle_start_build(self, conversation_id: Optional[int], notes: str):
        # choose active phase if none
        # maybe refresh snapshot
        # create initial ExecutionRun for top unblocked task

    def handle_continue_build(self, conversation_id: Optional[int], notes: str):
        # resume unfinished run or start new one

    def has_run_awaiting_approval(self) -> bool: ...
    def has_unfinished_run(self) -> bool: ...
    def should_start_new_run(self) -> bool: ...
    def advance_run(self) -> dict: ...
    def start_run_for_next_task(self) -> ExecutionRun: ...
    def explain_plan(self) -> dict: ...


Task selection heuristics:

Candidate tasks:

status="open".

source_plan_node_id in subtree of active_phase_node_id.

All TaskDependencies depends_on_task_id have status="done".

Sort by:

PlanNode.priority (high first).

Task size (XS/S before M/L/XL when ramping).

PlanNode.order_index.

Run creation:

For selected task:

Create ExecutionRun(run_type="implement_feature", started_by="manager").

Ask code_worker to produce step plan without calling tools yet.

Convert step plan JSON into ExecutionSteps with correct tool + input_payload.

Set steps status pending.

Advance run:

Find earliest ExecutionStep with status="pending".

Based on autonomy_mode + tool + safety:

In suggest: mark needs_approval, don’t execute.

In semi_auto: auto‑execute safe steps (reads/search/tests), require approval for writes or unsafe commands.

In full_auto: auto‑execute everything that passes safety + alignment.

After last step completes:

If tests successful, mark task done.

Update PlanNode summary/status.

Optionally log Decision (“Implemented X v1”).

Concurrency:

should_start_new_run uses max_parallel_runs + count of running/awaiting_approval runs.

Manager explain‑plan endpoint:

GET /projects/{project_id}/manager/plan


Returns:

{
  "active_phase": {...},
  "next_tasks": [...],
  "runs_in_progress": [...],
  "summary": "..."
}


Front‑end: “Explain current plan” button to show this in Notes/Tasks tab.

4.4 Autopilot tick endpoint

File: backend/app/api/main.py.

@app.post("/projects/{project_id}/autopilot_tick")
def autopilot_tick(project_id: int):
    project = get_project(...)
    if project.autonomy_mode == "off" or project.autopilot_paused:
        return {"status": "idle"}

    manager = ManagerAgent(project_id)

    if manager.has_run_awaiting_approval():
        return {"status": "waiting_for_approval"}

    if manager.has_unfinished_run():
        action = manager.advance_run()
        return {"status": "advanced_run", "details": action}

    if manager.should_start_new_run():
        run = manager.start_run_for_next_task()
        return {"status": "started_run", "run_id": run.id}

    return {"status": "nothing_to_do"}


Autopilot should be idempotent and safe to call frequently.

4.5 Frontend heartbeat & controls

File: frontend/src/App.tsx.

When:

A project is open, and

autonomy_mode != "off", and

!autopilot_paused

Start an interval calling /projects/{id}/autopilot_tick every 30–60s (with simple backoff if repeatedly “idle”).

Header shows:

Mode: Off / Suggest / Semi / Full.

Status pill: Idle / Running / Waiting for approval / Paused / Error.

Controls:

Autonomy mode dropdown.

“Pause/Resume Autopilot” button toggling autopilot_paused.

On responses:

"started_run" → toast “Manager started run #X for task Y”.

"advanced_run" → update Runs panel.

"waiting_for_approval" → highlight Runs tab with “Manager waiting for you” badge.

5. Phase 5 – UX, Docs, QA
5.1 CEO dashboard

Use existing Usage/Notes tabs to build a simple project dashboard.

Contents (pulled from DB + snapshot):

Active blueprint + phase.

Snapshot summary (1–2 sentences).

Task counts: open / in progress / done / blocked.

Runs: in progress / failed / completed.

Autopilot: mode + last tick status.

Recent Decisions list.

This can initially be a small panel in Notes tab or Usage tab.

5.2 Docs to update

docs/SYSTEM_OVERVIEW.md: add section “Autopilot manager & workers” describing architecture. 

SYSTEM_OVERVIEW

docs/SYSTEM_MATRIX.md: new rows for Blueprint/PlanNode, ExecutionRun/Step, Manager/Autopilot endpoints and UI surfaces. 

SYSTEM_MATRIX

docs/API_REFERENCE.md: document new endpoints:

/projects/{id}/blueprints, /blueprints/{id}, /blueprints/{id}/generate_plan, /blueprints/{id}/compare_to_parent.

/plan_nodes/{id}/generate_tasks.

/projects/{id}/runs, /runs/{id}, /runs/{id}/advance, /runs/{id}/rollback.

/projects/{id}/autopilot_tick, /projects/{id}/next_tasks, /projects/{id}/manager/plan. 

API_REFERENCE

docs/USER_MANUAL.md: new chapters:

“Blueprints & Plans (500k‑word specs)”.

“Automation Runs & Runs panel”.

“Autopilot modes & safety”. 

USER_MANUAL

docs/DEV_GUIDE.md: where ManagerAgent, workers, runs, context builder live; how to extend them. 

DEV_GUIDE

docs/AGENT_GUIDE.md: updated expectations for agents re: autopilot, safe ops, and new tools. 

AGENT_GUIDE

docs/OPERATIONS_RUNBOOK.md: add runbook steps for exercising autopilot/runs in QA. 

OPERATIONS_RUNBOOK

docs/TEST_PLAN.md, docs/TEST_REPORT_TEMPLATE.md: add phases and cases for autopilot & blueprint ingestion.

docs/PROGRESS.md, docs/TODO_CHECKLIST.md: track implementation status and follow‑ups.

5.3 QA & smoke tests

New QA scripts in qa/:

qa/blueprints_probe.py:

Seed a doc.

Create blueprint, generate plan, generate tasks for one PlanNode.

Assert PlanNodes + Tasks exist and are linked.

qa/runs_autopilot_probe.py:

Seed tiny project with 1 task “Write hello file”.

Create a run and let autopilot tick until completion (in semi_auto with no writes, or in a sandbox).

Assert run moves planned → running → completed and file contents are correct.

Extend docs/TEST_PLAN.md with scenarios:

H-Blueprint-01: upload large spec, generate plan, generate tasks.

H-Autopilot-01: semi_auto executes safe steps, waits for approvals on writes.

H-Autopilot-02: full_auto respects terminal allowlist and supports rollback.

Make sure qa/run_smoke.py includes at least blueprints probe & runs probe in its list.

6. How to drive Cursor with this plan
6.1 Create AUTOPILOT_PLAN.md

In docs/AUTOPILOT_PLAN.md:

Paste this entire spec.

Optionally add a short preface explaining this is the design for “Blueprint → Manager → Autopilot”.

6.2 Phase‑by‑phase Cursor prompts

Phase 1 – Models + endpoints + basic Plan UI

“Open docs/AUTOPILOT_PLAN.md and implement everything under Phase 1 in the backend and Tasks tab:

Add the Blueprint / PlanNode / PlanNodeTaskLink / TaskDependency / BlueprintIngestionJob models to backend/app/db/models.py.

Add the blueprint/plan endpoints to backend/app/api/main.py and a new backend/app/services/blueprints.py.

Add the Blueprint selector + Plan tree + task filtering to the Tasks tab in frontend/src/App.tsx.
Please keep changes focused and show me all diffs when done.”

Then run:

python -m qa.run_smoke

Quick manual check: create a dummy blueprint, run generate_plan, see Plan tree in UI.

Phase 2 – Summaries, snapshot, context builder, alignment

“Implement Phase 2 from docs/AUTOPILOT_PLAN.md:

ConversationSummary and ProjectSnapshot models & helpers.

refresh_project_snapshot and /projects/{id}/snapshot/refresh.

context_builder.py and wiring into the chat endpoint.

alignment.py with check_alignment.
Do not change the UI yet beyond adding a snapshot card in Notes and pinning snapshot in Docs.”

Then re‑run smoke tests and some manual chat sessions to verify that behavior is stable.

Phase 3 – Execution runs & workers

“Implement Phase 3 from docs/AUTOPILOT_PLAN.md:

Add ExecutionRun/ExecutionStep models.

Add runs endpoints and rollback.

Implement worker wrappers and tool‑calling logic in openai_client.

Add a minimal Runs panel in the frontend.
Keep file edits confined to the mentioned files and wire into existing Files/Terminal/Search APIs.”

Phase 4 – Manager & Autopilot

“Implement Phase 4 from docs/AUTOPILOT_PLAN.md:

Add autonomy fields to Project and intent classifier.

Implement ManagerAgent logic and /projects/{id}/autopilot_tick.

Add Autopilot controls in the header and hook up the heartbeat.

Implement /projects/{id}/next_tasks and /projects/{id}/manager/plan.
Add minimal UI surfaces for next recommended tasks and manager’s plan explanation.”

Phase 5 – UX, docs, QA

“Apply Phase 5 from docs/AUTOPILOT_PLAN.md:

CEO dashboard view.

Docs updates.

QA probes for blueprints and autopilot.

Any small UX polish for Runs panel and Plan view.”

After each phase, run:

Backend smoke python -m qa.run_smoke.

npm run build and at least npm run test:e2e where relevant.