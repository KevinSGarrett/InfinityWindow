InfinityWindow – Full User & Admin Manual

This manual explains, step by step, how to:

Install and configure InfinityWindow

Run the backend and frontend

Understand the UI and core concepts

Use every major feature (chat, tasks, docs, files, terminal, notes, memory, usage)

Maintain, test, and troubleshoot the system

It is written so that a new user can go from zero to a fully working setup, and an advanced user can learn how to extend and debug it.

Table of Contents

What InfinityWindow Is (and How to Think About It)

Quick Start (If You’re Impatient)

System Requirements & Prerequisites

Getting the Code & Directory Layout

Backend Setup (FastAPI)

Frontend Setup (React + Vite)

First Run: Creating a Project & Starting a Conversation

Chat, Modes, and How Replies Are Generated

Right Column Tabs: Tasks, Files, Docs, Search, Terminal, Usage, Notes, Memory

Working with Files & AI-Powered File Edits

Terminal Integration & AI-Proposed Commands

Project Instructions, Decision Log, Folders & Memory

Usage & Cost Tracking

Keyboard Shortcuts & Command Palette

Running a QA / Staging Copy (Optional)

Testing & QA Workflows

Configuration, Models & Environment Variables

Maintenance, Resetting & Updating

Known Limitations & Workarounds

FAQ & Troubleshooting

1. What InfinityWindow Is (and How to Think About It)

InfinityWindow is a local AI‑assisted workspace for a software project (or any long‑running initiative).

It ties together, in a single app:

Chat with an LLM (linked to your files and docs)

Tasks / TODOs

Documents & knowledge (ingested text and code)

Filesystem access (view/edit files, AI file refactors)

Terminal commands (including AI‑suggested commands)

Notes, decisions, and long‑term memory

Usage & cost tracking

Mental model:

Think of InfinityWindow as a “project brain” that sits on top of your repo.
You talk to it; it sees your files, remembers decisions, generates tasks, and helps you run commands and edits.

Use one Project per repo or major initiative, then use:

Conversations to talk through work

Tasks to track what’s left

Docs & Memory to record what you know

Files & Terminal to change and run things

Notes & Decisions to keep a history of choices

2. Quick Start (If You’re Impatient)

If you just want to see it running quickly, follow this section. Details are in later sections.

2.1 Install Prerequisites

On Windows 10/11:

Install:

Python 3.11+ (3.12 confirmed to work) – check:

python --version


Node.js + npm (recent LTS) – check:

node --version
npm --version


Git (optional if you just download a ZIP).

Get an OpenAI API key (or equivalent provider) and keep it handy.

2.2 Get the Code
cd C:\
git clone https://github.com/KevinSGarrett/InfinityWindow.git
cd C:\InfinityWindow


(or extract a ZIP to C:\InfinityWindow).

2.3 Start the Backend
cd C:\InfinityWindow\backend
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
# Create backend/.env with your API key (see §5.3)
uvicorn app.api.main:app --reload


Check health:

Invoke-RestMethod http://127.0.0.1:8000/health


You should see JSON like:

{"status":"ok","service":"InfinityWindow","version":"0.3.0"}

2.4 Start the Frontend

In another PowerShell window:

cd C:\InfinityWindow\frontend
npm install
npm run dev


Open the printed URL (usually http://127.0.0.1:5173) in your browser.

You should see:

InfinityWindow header (with version)

Three main columns:

Left: Projects & Conversations

Middle: Chat

Right: Tabs (Tasks, Files, Docs, etc.)

2.5 First Conversation

In the Project selector (top‑left), select the default project or create one (see §7).

Click + New chat.

Type something like:

“Help me review this repo and suggest an initial cleanup plan.”

Press Enter and wait for the assistant’s reply.

You’re now using InfinityWindow.

3. System Requirements & Prerequisites
3.1 Supported OS & Shell

OS: Windows 10 / 11 (primary development & testing environment).

Shells:

PowerShell – recommended and used in examples.

cmd.exe works if you adapt commands accordingly.

3.2 Required Software

Install:

Python 3.11 or newer

Ensure python is on your PATH.

Node.js (LTS) + npm

Ensure node and npm are on your PATH.

Git

For cloning and updating the repo.

3.3 API Credentials

You need an OpenAI API key or compatible key for whichever provider the backend is configured to use.

The backend expects this key (and model names) via a .env file in backend/ (covered in §5.3).

3.4 Optional Tools

Optional but helpful:

GNU Make

For running make ci in a QA/staging copy.

Playwright

For UI regression tests of the frontend.

4. Getting the Code & Directory Layout
4.1 Default Location

For consistency, this manual assumes the repo is located at:

C:\InfinityWindow

You can choose another directory; just adapt paths accordingly.

4.2 Cloning or Downloading

Using Git:

cd C:\
git clone https://github.com/KevinSGarrett/InfinityWindow.git
cd C:\InfinityWindow


Using ZIP:

Download the ZIP from GitHub.

Extract it so the root folder is C:\InfinityWindow.

4.3 High-Level Directory Structure

Key directories:

backend\
FastAPI application, SQLite DB, vector store (Chroma), LLM client, APIs.

frontend\
React + TypeScript SPA (UI).

docs\
Project docs (test plans, progress reports, manuals).

scratch\
Misc test files (e.g., scratch/test-notes.txt).

Typical runtime artefacts:

backend\infinitywindow.db – main SQLite DB.

backend\chroma_data\ – vector store for docs/messages.

5. Backend Setup (FastAPI)

All backend commands assume:

cd C:\InfinityWindow\backend

5.1 Create and Activate Virtual Environment

Recommended for isolating Python dependencies.

python -m venv .venv
.\.venv\Scripts\Activate.ps1


Your prompt should now show something like (backend\.venv).

Note: Always activate this venv before running backend commands.

5.2 Install Dependencies
pip install -r requirements.txt


If this fails, check:

That you’re in the correct directory (backend).

That the venv is active.

5.3 Configure Environment Variables (.env)

Create backend\.env (if not present) and add at least:

OPENAI_API_KEY=sk-...

# Optional – override model routing (examples)
OPENAI_MODEL_AUTO=gpt-5.1
OPENAI_MODEL_FAST=gpt-5-nano
OPENAI_MODEL_DEEP=gpt-5-pro
OPENAI_MODEL_BUDGET=gpt-4.1-nano
OPENAI_MODEL_RESEARCH=o3-deep-research
OPENAI_MODEL_CODE=gpt-5.1-codex


Important notes:

OPENAI_API_KEY must be valid or you’ll get 401/500 errors on chat calls.

If o3-deep-research is not available on your account, set OPENAI_MODEL_RESEARCH to a model you do have, or avoid research mode (see §17).

5.4 Database & Vector Store Initialization

On first run:

The backend automatically creates infinitywindow.db and chroma_data/ as needed.

You don’t need to run migrations manually.

If schemas change (e.g., after updating the code) and you see errors like:

sqlite3.OperationalError: no such column ...


you can reset:

# With backend server stopped
Remove-Item C:\InfinityWindow\backend\infinitywindow.db -Force
Remove-Item C:\InfinityWindow\backend\chroma_data -Recurse -Force


Restarting the backend will recreate them.

Warning: Deleting these files wipes existing projects, conversations, tasks, docs, etc.
Make backups first if you care about the data.

5.5 Running the Backend

With venv active:

uvicorn app.api.main:app --reload


By default, backend listens on:

http://127.0.0.1:8000

Verify health endpoint:

Invoke-RestMethod http://127.0.0.1:8000/health


Expected JSON:

{"status":"ok","service":"InfinityWindow","version":"0.3.0"}


If this fails, see troubleshooting (§20).

6. Frontend Setup (React + Vite)
6.1 Install Frontend Dependencies
cd C:\InfinityWindow\frontend
npm install


This downloads all JavaScript dependencies.

6.2 Run the Dev Server
npm run dev


You should see output like:

  VITE vX.Y.Z  ready in N ms
  ➜  Local:   http://127.0.0.1:5173/


Open the printed URL in your browser.

6.3 Verifying the UI

A successful load shows:

Top bar: InfinityWindow logo/title + version pill.

Left column: Project selector and conversation list.

Center: Chat area with input at bottom.

Right column: Tabs (Tasks, Files, Docs, Search, Terminal, Usage, Notes, Memory).

If the UI loads but shows errors like “Cannot connect to backend”:

Confirm the backend is running on http://127.0.0.1:8000.

Check that your browser didn’t block requests (CORS, extensions, etc.).

7. First Run: Creating a Project & Starting a Conversation

This section explains how to go from a blank state to your first project and chat.

7.1 Projects: What They Represent

A Project ties together:

A logical name (“InfinityWindow Main”, “Client X Site”)

A description

A local_root_path (usually a repo directory, e.g., C:\InfinityWindow)

All related:

Conversations

Tasks

Docs

Files

Notes & decisions

Memory items

You typically use one project per repo or major initiative.

7.2 Creating or Selecting a Project (UI)

In the top‑left:

Use the Project selector to:

Choose an existing project (if any).

Or create a new one (if the UI exposes a “New project” option — implementation may vary).

If no project exists, the backend may auto‑create a Default Project pointing at your repo root.

7.3 Creating a Project via API (Optional/Admin)

You can also create projects via REST, e.g. from PowerShell:

$body = @{
  name = "Demo Project"
  description = "Main InfinityWindow playground"
  local_root_path = "C:\InfinityWindow"
} | ConvertTo-Json

Invoke-RestMethod -Method Post `
  -Uri http://127.0.0.1:8000/projects `
  -ContentType 'application/json' `
  -Body $body


The frontend will then list this project.

7.4 Starting Your First Conversation

Once a project is selected:

In the left column, click + New chat.

Your new conversation appears in the list.

In the middle column (chat area):

Type a message (e.g., “What does this repo do?”).

Press Enter to send (Shift+Enter adds a newline).

Watch:

Your message appears on the right (or left, depending on UI theme).

A “Thinking…” or spinner shows while the backend calls the LLM.

The assistant reply appears.

Conversations are saved with:

Messages

Associated tasks (via auto‑task extraction)

Any attached docs/memory references

You can rename conversations, and organize them with folders (see §12.3).

8. Chat, Modes, and How Replies Are Generated
8.1 Sending Messages

Basic flow:

Type in the chat input.

Press Enter (or click Send).

The frontend sends your message plus recent conversation history to /chat.

The backend:

Stores your message.

Retrieves relevant:

Memory items

Docs

System & project instructions

Calls the configured LLM.

Stores the assistant reply.

Optionally:

Extracts tasks from the conversation.

Proposes a terminal command.

Emits AI file edits.

You see:

User messages (you)

Assistant messages (InfinityWindow)

Any inline suggestions or references.

8.2 Chat Modes

You can choose a mode that maps to different models:

auto – default, general‑purpose

fast – cheaper, faster model

deep – more powerful, more expensive reasoning

budget – very low cost, lower quality

research – for deep research tasks

code – tuned for code-heavy tasks

Mapping is controlled by environment variables (see §17).

Current behavior & caveats:

fast, deep, budget, code – use the configured models reliably.

research – can fail with 500 if OPENAI_MODEL_RESEARCH is set to a model your account doesn’t have.

auto – currently routes to a single model; it does not yet adapt the model based on task type.

Practical usage:

Use code for refactors, debugging suggestions, and code generation.

Use deep when you want careful, multi‑step reasoning.

Use fast for quick questions and low‑stakes answers.

Use budget when cost is more important than quality.

Use auto as a default when you don’t want to think about it.

9. Right Column Tabs: Tasks, Files, Docs, Search, Terminal, Usage, Notes, Memory

The right column is a mode panel. Keyboard shortcuts (Alt+1–8) switch between tabs (see §14.1).

High‑level mapping:

Tasks – Project TODOs (manual + AI‑generated).

Files – View and edit files under the project root.

Docs – Ingest and inspect docs/repo embeddings.

Search – Search messages or docs.

Terminal – Run commands, view AI proposals.

Usage – Tokens and cost per conversation.

Notes – Project instructions and decision log.

Memory – Long-term memory items.

Sections 9–13 explain these in more detail.

10. Working with Files & AI-Powered File Edits
10.1 Files Tab: Browsing & Editing

In the Files tab you can:

Browse the project’s folder structure.

Open files for reading or editing.

Save changes to disk.

Typical UI elements:

Path display – Shows current path relative to local_root_path.

Folder tree/list – Click folders to enter them; click files to open them.

Editor area – Shows file content; usually an editable textarea.

“Show original” toggle – View the file as currently on disk, read‑only.

“Save file” button – Sends edits to /fs/write and writes to disk.

Safety rules:

All paths are relative to local_root_path.

The backend rejects:

Absolute paths.

Paths containing .. (to prevent escaping project root).

Tip: Use Git for version control. Let InfinityWindow make file changes, then inspect git diff before committing.

10.2 AI File Edits via UI

The UI usually offers an AI file edit panel:

Select or type the file path (backend/app/api/main.py, etc.).

Write an instruction, e.g.:

“Add structured logging when requests fail with status >= 400.”

Click Preview edit:

The backend calls the LLM with an edit instruction and current file contents.

You see a diff (additions/deletions).

If acceptable, click Apply AI edit:

The backend writes changes to the file.

Best practices:

Always preview before applying.

Keep instructions specific:

“Add guard rails when OPENAI_MODEL_RESEARCH is unavailable” is better than “Improve error handling”.

Run tests (or at least npm run build / pytest) after large changes.

10.3 AI File Edits Triggered from Chat

Beyond the Files tab, the assistant can propose edits during chat.

Under the hood:

The system prompt allows the model to emit special <<AI_FILE_EDIT>> blocks describing changes.

The backend interprets these blocks and applies them.

The raw blocks are removed from the displayed message, so you only see the prose explanation.

What you may see:

The assistant says:

“I’ve refactored openai_client.py to centralize model mapping. Here’s what changed …”

In the Files tab, the file actually changed accordingly.

Tip: If you prefer manual control, you can disable or ignore auto‑applied edits and instead ask for diffs and patches you apply yourself.

11. Terminal Integration & AI-Proposed Commands
11.1 AI-Proposed Commands

The assistant can propose commands based on the conversation, such as:

Running tests

Installing dependencies

Building the frontend

Running scripts

Internally:

The assistant appends a terminal_command_proposal JSON object to its reply.

The frontend reads this and shows it in the Terminal tab.

In the Terminal tab you’ll see:

Suggested working directory (cwd)

Command (e.g., npm run build)

Reason (why it suggested this)

From there you can:

Click Run command:

Executes via /terminal/run.

Output is captured and summarized back into the conversation.

Or Dismiss if you don’t want to run it.

Safety: You are always in control. The assistant cannot run anything without your explicit action.

11.2 Manual Terminal Commands

You can also run commands yourself.

In the Terminal tab:

Choose cwd:

backend, frontend, or . (project root).

Enter a command, e.g.:

pytest -q

npm run build

python -m pip list

Click Run.

The backend:

Restricts cwd to subdirectories of local_root_path.

Captures stdout/stderr.

Returns output to the UI.

History:

Previously run commands are saved.

You can re-run them from history instead of retyping.

Tip: Use this instead of alt‑tabbing between a terminal and browser for routine project commands.

12. Project Instructions, Decision Log, Folders & Memory
12.1 Project Instructions (Notes Tab)

In the Notes tab, you’ll find a Project Instructions editor.

Use it to describe how the assistant should behave for this project:

Examples:

“Always reply in Markdown.”

“Prefer PowerShell examples over Bash.”

“This repo uses poetry, not pip.”

“Never commit directly to main; always create a branch.”

When you click Save:

The backend stores instruction_text on the project.

These instructions are injected into the system prompt for all future /chat calls in this project.

Best practice: Keep these instructions short, clear, and stable. Update them when project patterns change.

12.2 Decision Log (Notes Tab)

Also in Notes is a Decision log:

Each entry includes:

Title (e.g., “Adopt Playwright for UI tests”)

Category (e.g., “Testing”, “Architecture”, “Process”)

Details (free‑text description)

Optional reference to the conversation where the decision was made

Use it to record:

Design decisions

Tool choices

Process agreements

Any decision that future you will ask “Why did we do that?”

Benefits:

Reduces repeated debates.

Gives the assistant context on why things are the way they are.

Supports onboarding of new team members.

12.3 Conversation Folders (Left Sidebar)

In the left sidebar:

You can create folders (e.g., “Backend”, “Frontend”, “Docs”, “Experiments”).

Give them names and colors.

Drag or assign conversations into folders.

This helps:

Keep your conversation list manageable.

Group related work (by feature, sprint, or topic).

Filter searches by folder_id in backend APIs.

13. Usage & Cost Tracking

The Usage tab shows per‑conversation usage:

Total tokens in (prompt) and out (completion).

Estimated cost in USD.

A list of individual usage records:

Model name

Tokens

Timestamp

Backend:

Each generate_reply_from_history call creates a UsageRecord.

/conversations/{id}/usage aggregates them for the frontend.

Use this to:

Keep an eye on cost.

Identify expensive patterns (e.g., huge context windows with deep mode).

Compare cost between modes (fast vs deep vs budget).

Tip: If costs spike, try:

Reducing the number of ingested documents in context,

Using fast or budget for minor tasks,

Summarizing long threads and starting fresh conversations.

14. Keyboard Shortcuts & Command Palette
14.1 Tab Switching (Right Column)

By default:

Alt+1 – Tasks

Alt+2 – Files

Alt+3 – Docs

Alt+4 – Search

Alt+5 – Terminal

Alt+6 – Usage

Alt+7 – Notes

Alt+8 – Memory

These let you keep your hands on the keyboard and switch tools quickly.

14.2 Command Palette

If implemented (depending on your frontend build), a command palette may be opened with something like Ctrl+K.

It’s generally used to:

Jump between tabs or sections.

Focus specific inputs.

Trigger common actions.

Check the UI hints or keybinding docs in the repo for the exact shortcut if it’s enabled.

15. Running a QA / Staging Copy (Optional)

If you’re actively developing or QA’ing InfinityWindow itself, it can be helpful to keep a separate QA copy.

15.1 Creating a QA Copy

Use robocopy to clone the directory, excluding heavy folders:

robocopy C:\InfinityWindow C:\InfinityWindow_QA /MIR /XD .git .venv node_modules


Then:

In C:\InfinityWindow_QA\backend:

Create and activate a new .venv.

Run pip install -r requirements.txt.

Start uvicorn.

In C:\InfinityWindow_QA\frontend:

Run npm install.

Run npm run dev.

This allows:

A “clean” environment for tests.

Separate DB and vector store from your main working copy.

15.2 Makefile CI in QA Copy

A typical Makefile in C:\InfinityWindow_QA might include:

ci:
	@echo "Running backend tests..."
	-cd backend && pytest
	@echo "Running frontend build..."
	cd frontend && npm run build


Run:

cd C:\InfinityWindow_QA
make ci


Notes:

The leading - in -cd backend && pytest means failures (e.g., “no tests ran”) won’t stop the whole make ci.

npm run build runs a production build of the frontend and will catch TypeScript errors.

16. Testing & QA Workflows
16.1 Manual QA

Typical manual QA includes:

Environment checks

Backend health (/health)

Frontend loads and connects

Core flows

Create project, start conversation, send/receive messages.

Manually add tasks; verify they appear and toggle.

Use Files tab to open and edit files.

Ingest docs; confirm doc search.

Test AI file edits on a small file.

Advanced flows

AI‑proposed terminal commands.

Notes/decision log updates.

Memory creation and retrieval.

Usage panel correctness.

Regression checks

Confirm known bugs remain fixed.

Confirm known limitations are unchanged or improved.

(Your repo may include detailed test plans and templates in docs/.)

16.2 Automated UI Tests with Playwright

In the QA frontend (C:\InfinityWindow_QA\frontend):

Ensure dev server is running on a predictable port, e.g.:

npm run dev -- --host 127.0.0.1 --port 5174


Run Playwright tests:

npx playwright test


Example: A test like tests/right-column.spec.ts might verify that:

Each right‑column tab can be clicked.

“Active” styling correctly updates.

17. Configuration, Models & Environment Variables
17.1 Core Environment Variables (backend/.env)

At minimum:

OPENAI_API_KEY=sk-...


Optional overrides:

OPENAI_MODEL_AUTO=...
OPENAI_MODEL_FAST=...
OPENAI_MODEL_DEEP=...
OPENAI_MODEL_BUDGET=...
OPENAI_MODEL_RESEARCH=...
OPENAI_MODEL_CODE=...

17.2 Mode–Model Mapping

The backend usually maps:

Mode auto → OPENAI_MODEL_AUTO

Mode fast → OPENAI_MODEL_FAST

Mode deep → OPENAI_MODEL_DEEP

Mode budget → OPENAI_MODEL_BUDGET

Mode research → OPENAI_MODEL_RESEARCH

Mode code → OPENAI_MODEL_CODE

If a variable is not set, defaults are used (see the backend code for actual defaults).

17.3 Research Mode Caution

If OPENAI_MODEL_RESEARCH points to something like o3-deep-research and your account doesn’t have access:

Any chat using mode="research" will likely fail with a 500.

Workaround:

Map OPENAI_MODEL_RESEARCH to a known-good model.

Or avoid research mode until you have access.

18. Maintenance, Resetting & Updating
18.1 Resetting the Database & Vector Store

If:

You break the schema by checking out a different branch,

Or you want a completely clean slate,

you can remove the DB and vector store:

# With backend stopped
Remove-Item C:\InfinityWindow\backend\infinitywindow.db -Force
Remove-Item C:\InfinityWindow\backend\chroma_data -Recurse -Force


Then restart the backend; it will recreate them.

Warning: This deletes all projects, chats, tasks, docs, memory, etc.

18.2 Updating the Code

If you installed via Git:

cd C:\InfinityWindow
git pull


You may need to:

Reinstall backend deps:

cd backend
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt


Reinstall frontend deps:

cd ..\frontend
npm install


If the update changes DB schema, you might need to reset DB as in §18.1 or run any official migration script the repo provides.

18.3 Backups

Because state is stored locally:

You can back up:

backend\infinitywindow.db

backend\chroma_data\

Restoring these files restores all saved state.

For important projects, periodically copy these files somewhere safe or include them in your general backup strategy.

19. Known Limitations & Workarounds

As of the last documented QA run (2025‑12‑02), the following limitations are known:

19.1 Message Search Not Returning Results

/search/messages returns no hits even when unique tokens are present.

UI message search therefore appears “empty”.

Workaround:

Use doc search to find information in ingested docs.

Skim conversation manually or use memory items for critical long‑term info.

Track status of this bug in the repo’s issues or progress docs.

19.2 Research Mode Errors

mode="research" fails when OPENAI_MODEL_RESEARCH points to an unavailable model (e.g., o3-deep-research without access).

Workaround:

Set OPENAI_MODEL_RESEARCH to a supported model.

Or avoid research mode and use deep instead.

19.3 Auto Mode Not Adaptive

auto currently maps to a single model.

It does not dynamically choose models based on task type.

Workaround:

Manually select fast, deep, code, etc., as needed.

19.4 Task Auto-Maintenance Is Append-Only

The backend can add tasks automatically based on conversation.

It does not:

Mark tasks as done when you say “X is complete”.

Merge or reorder tasks.

This can result in duplicates or overlapping tasks.

Workaround:

Treat auto tasks as suggestions.

Manually:

Mark tasks done.

Deduplicate or merge similar tasks.

Use explicit phrasing when you want a task captured.

20. FAQ & Troubleshooting
20.1 Frontend Loads but Chat Fails With 500

Possible causes:

Missing or invalid OPENAI_API_KEY.

OPENAI_MODEL_* points to a model you don’t have access to.

Backend not actually running at http://127.0.0.1:8000.

Steps:

Check backend\.env.

Confirm backend health:

Invoke-RestMethod http://127.0.0.1:8000/health


Look at backend console for stack traces.

20.2 Cannot Create / Save Files

Symptoms:

Error messages about path traversal or invalid path.

Causes:

Attempting to edit files outside local_root_path.

Using absolute paths or .. segments.

Fix:

Use paths inside the project root.

Use relative paths (e.g., backend/app/api/main.py, not C:\Windows\...).

20.3 AI File Edits Break the Code

Symptoms:

After an AI edit, code no longer runs or tests fail.

Best practices:

Use git diff after any AI edit to see exactly what changed.

If changes are not acceptable:

git restore or revert the file.

Prefer incremental edits:

Change small sections at a time.

Run tests between steps.

20.4 High LLM Costs

If the Usage tab shows unexpectedly high costs:

Check if you’re using deep or research more than necessary.

Avoid very long conversations without summarizing.

Reduce the number of long docs you ingest simultaneously.

Use fast or budget for routine tasks.

20.5 Playwright Tests Can’t Find the App

Symptoms:

Playwright test failures with “page not reachable” errors.

Checklist:

Confirm dev server is running:

npm run dev -- --host 127.0.0.1 --port 5174


Confirm Playwright config matches:

Base URL set to http://127.0.0.1:5174 (or whatever you use).