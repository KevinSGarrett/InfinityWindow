# file: C:\InfinityWindow\backend\app\llm\openai_client.py
# hypothesis_version: 6.148.7

[0.0, 0.05, 0.25, 0.4, 1.25, 2.0, 10.0, 15.0, 120.0, 1000.0, 120, 800, '#include', '=>', 'OPENAI_API_KEY', 'OPENAI_MODEL_AUTO', 'OPENAI_MODEL_FAST', '[{};]', '```', 'analysis', 'architecture', 'auto', 'auto_routes', 'budget', 'case study', 'citations', 'class ', 'code', 'compare', 'completion_tokens', 'const ', 'content', 'cost_estimate', 'deep', 'def ', 'fallback_attempts', 'fallback_success', 'fast', 'function ', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4o', 'gpt-5', 'gpt-5-codex', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-pro', 'gpt-5.1', 'gpt-5.1-codex', 'gpt-oss-', 'import ', 'ingestion pipeline', 'input', 'input_tokens', 'interface ', 'investigate', 'let ', 'literature review', 'market', 'max_output_tokens', 'max_tokens', 'messages', 'milestone', 'milestones', 'mini', 'model', 'multi quarter', 'multi-quarter', 'nano', 'o3', 'o3-deep-research', 'o4', 'output', 'output_text', 'output_tokens', 'plan for', 'private ', 'pro', 'prompt_tokens', 'public ', 'reference', 'research', 'roadmap', 'role', 'rollback', 'rollbacks', 'schema evolution', 'sources', 'statistical', 'strategy', 'survey', 'system design', 'telemetry', 'temperature', 'text', 'timeline', 'tokens_in', 'tokens_out', 'total_tokens', 'usage', 'user', 'value', 'var ', 'whitepaper']